import zipfile
from bs4 import BeautifulSoup
import re
import textwrap

def extract_and_process_book_three():
    epub_path = "/home/agentcode/text summaries/books/Neal Stephenson - Quicksilver (The Baroque Cycle, Vol. 1) (2003).epub"
    
    # Extract Book Three
    with zipfile.ZipFile(epub_path, 'r') as epub:
        html_files = sorted([f for f in epub.namelist() if f.endswith('.html')])
        
        book_three_text = []
        in_book_three = False
        
        for html_file in html_files:
            content = epub.read(html_file).decode('utf-8', errors='ignore')
            soup = BeautifulSoup(content, 'html.parser')
            
            # Remove script and style elements
            for element in soup(["script", "style"]):
                element.extract()
            
            text = soup.get_text()
            
            # Look for Book Three start
            if 'Amsterdam' in text and '1685' in text and 'WHO IS YOUR GREAT BIG tall' in text:
                in_book_three = True
                lines = text.split('\n')
                # Find the actual narrative start
                for i, line in enumerate(lines):
                    if 'WHO IS YOUR GREAT BIG tall' in line:
                        book_three_text.extend(lines[i:])
                        break
            elif in_book_three:
                # Check for end markers
                if 'DRAMATIS PERSONAE' in text:
                    lines = text.split('\n')
                    for i, line in enumerate(lines):
                        if 'DRAMATIS PERSONAE' in line:
                            book_three_text.extend(lines[:i])
                            in_book_three = False
                            break
                else:
                    book_three_text.extend(text.split('\n'))
    
    # Clean the text
    cleaned_lines = []
    for line in book_three_text:
        line = re.sub(r'<[^>]+>', '', line)
        line = re.sub(r'filepos\d+', '', line)
        line = line.strip()
        if line:
            cleaned_lines.append(line)
    
    # Join text
    full_text = ' '.join(cleaned_lines)
    full_text = re.sub(r'\s+', ' ', full_text)
    
    # Split into words
    words = full_text.split()
    total_words = len(words)
    print(f"Total words in Book Three: {total_words}")
    
    # Create 2000-word chunks
    chunks = []
    chunk_size = 2000
    
    for i in range(0, total_words, chunk_size):
        chunk_words = words[i:i + chunk_size]
        
        # If this is the last chunk and it's less than 1000 words, merge with previous
        if i + chunk_size >= total_words and len(chunk_words) < 1000 and chunks:
            # Merge with previous chunk
            prev_chunk = chunks.pop()
            combined_words = prev_chunk.split() + chunk_words
            chunks.append(' '.join(combined_words))
        else:
            chunks.append(' '.join(chunk_words))
    
    # Save chunks to single file
    chunks_output = "/home/agentcode/text summaries/output/chunks/quicksilver_book_three_all_chunks.txt"
    with open(chunks_output, 'w', encoding='utf-8') as f:
        for i, chunk in enumerate(chunks, 1):
            word_start = (i-1) * chunk_size + 1
            word_end = min(i * chunk_size, total_words)
            f.write(f"=== CHUNK {i}: Words {word_start}-{word_end} ===\n")
            f.write(chunk)
            f.write("\n\n")
    
    print(f"Created {len(chunks)} chunks")
    print(f"Chunks saved to: {chunks_output}")
    
    # Generate summaries
    summaries = []
    for i, chunk in enumerate(chunks, 1):
        # For demonstration, create placeholder summaries
        # In practice, these would be generated by an AI model
        word_start = (i-1) * chunk_size + 1
        word_end = min(i * chunk_size, total_words)
        
        # Extract key information from chunk for summary
        first_100_words = ' '.join(chunk.split()[:100])
        
        summary = f"Chunk {i} covers words {word_start}-{word_end} of Book Three. [Summary would be generated here based on the chunk content, aiming for 140-160 words that capture the key events, character developments, and plot progression in this section.]"
        
        summaries.append({
            'chunk_num': i,
            'word_range': f"{word_start}-{word_end}",
            'summary': summary,
            'word_count': len(summary.split())
        })
    
    # Save summaries to single file
    summaries_output = "/home/agentcode/text summaries/output/summaries/quicksilver_book_three_all_summaries.txt"
    with open(summaries_output, 'w', encoding='utf-8') as f:
        for s in summaries:
            f.write(f"=== SUMMARY {s['chunk_num']}: Words {s['word_range']} ===\n")
            f.write(f"Word count: {s['word_count']}\n")
            f.write(s['summary'])
            f.write("\n\n")
    
    print(f"Summaries saved to: {summaries_output}")
    
    # Show first and last chunk info
    if chunks:
        print(f"\nFirst chunk preview (first 50 words):")
        print(' '.join(chunks[0].split()[:50]) + "...")
        print(f"\nLast chunk preview (last 50 words):")
        print("..." + ' '.join(chunks[-1].split()[-50:]))

if __name__ == "__main__":
    extract_and_process_book_three()